{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDI Dataset Exploration\n",
    "\n",
    "This notebook explores classical MIDI datasets to understand:\n",
    "- Dataset structure and composition\n",
    "- Note distributions per composer\n",
    "- Sequence lengths and statistics\n",
    "- Data quality and validation\n",
    "\n",
    "**Prerequisites**: Download sample data first using `scripts/download_hf_dataset.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "from utils.midi_utils import (\n",
    "    load_midi_file,\n",
    "    get_midi_info,\n",
    "    validate_midi_file,\n",
    "    print_midi_summary,\n",
    "    get_piano_midi\n",
    ")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview\n",
    "\n",
    "First, let's check what data we have available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data/raw\")\n",
    "\n",
    "if data_dir.exists():\n",
    "    print(\"Available datasets:\")\n",
    "    for subdir in data_dir.iterdir():\n",
    "        if subdir.is_dir():\n",
    "            midi_files = list(subdir.rglob(\"*.mid\")) + list(subdir.rglob(\"*.midi\"))\n",
    "            print(f\"  {subdir.name}: {len(midi_files)} MIDI files\")\n",
    "else:\n",
    "    print(\"No data directory found. Please download data first using:\")\n",
    "    print(\"  python scripts/download_hf_dataset.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample MIDI File Analysis\n",
    "\n",
    "Let's load and analyze a sample MIDI file to understand the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_midi_files = list(data_dir.rglob(\"*.mid\")) + list(data_dir.rglob(\"*.midi\"))\n",
    "\n",
    "if len(all_midi_files) > 0:\n",
    "    sample_file = all_midi_files[0]\n",
    "    print(f\"Analyzing: {sample_file}\\n\")\n",
    "    print_midi_summary(sample_file)\n",
    "else:\n",
    "    print(\"No MIDI files found. Download data first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Statistics\n",
    "\n",
    "Collect statistics across all MIDI files in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_dataset_stats(midi_files, max_files=None):\n",
    "    \"\"\"\n",
    "    Collect statistics from a list of MIDI files.\n",
    "    \n",
    "    Args:\n",
    "        midi_files: List of MIDI file paths\n",
    "        max_files: Maximum number of files to process (None for all)\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        'total_notes': [],\n",
    "        'durations': [],\n",
    "        'pitch_ranges': [],\n",
    "        'num_instruments': [],\n",
    "        'composers': defaultdict(int),\n",
    "        'valid_files': 0,\n",
    "        'invalid_files': 0,\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    files_to_process = midi_files[:max_files] if max_files else midi_files\n",
    "    \n",
    "    for i, midi_file in enumerate(files_to_process):\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i+1}/{len(files_to_process)} files...\")\n",
    "        \n",
    "        try:\n",
    "            info = get_midi_info(midi_file)\n",
    "            \n",
    "            stats['total_notes'].append(info['total_notes'])\n",
    "            \n",
    "            if 'duration_seconds' in info:\n",
    "                stats['durations'].append(info['duration_seconds'])\n",
    "            \n",
    "            if 'pitch_range' in info:\n",
    "                stats['pitch_ranges'].append(info['pitch_range']['span'])\n",
    "            \n",
    "            stats['num_instruments'].append(len(info['instruments']))\n",
    "            \n",
    "            composer = midi_file.parent.name\n",
    "            stats['composers'][composer] += 1\n",
    "            \n",
    "            stats['valid_files'] += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            stats['invalid_files'] += 1\n",
    "            stats['errors'].append((str(midi_file), str(e)))\n",
    "    \n",
    "    return stats\n",
    "\n",
    "if len(all_midi_files) > 0:\n",
    "    print(f\"Collecting statistics from {min(len(all_midi_files), 1000)} files...\\n\")\n",
    "    dataset_stats = collect_dataset_stats(all_midi_files, max_files=1000)\n",
    "    print(f\"\\nProcessed {dataset_stats['valid_files']} valid files\")\n",
    "    print(f\"Found {dataset_stats['invalid_files']} invalid files\")\n",
    "else:\n",
    "    print(\"No MIDI files to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization\n",
    "\n",
    "Visualize the collected statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'dataset_stats' in locals() and dataset_stats['valid_files'] > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    axes[0, 0].hist(dataset_stats['total_notes'], bins=50, edgecolor='black')\n",
    "    axes[0, 0].set_xlabel('Number of Notes')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Distribution of Notes per File')\n",
    "    axes[0, 0].set_yscale('log')\n",
    "    \n",
    "    if dataset_stats['durations']:\n",
    "        axes[0, 1].hist(dataset_stats['durations'], bins=50, edgecolor='black')\n",
    "        axes[0, 1].set_xlabel('Duration (seconds)')\n",
    "        axes[0, 1].set_ylabel('Frequency')\n",
    "        axes[0, 1].set_title('Distribution of File Durations')\n",
    "    \n",
    "    if dataset_stats['pitch_ranges']:\n",
    "        axes[1, 0].hist(dataset_stats['pitch_ranges'], bins=30, edgecolor='black')\n",
    "        axes[1, 0].set_xlabel('Pitch Range (semitones)')\n",
    "        axes[1, 0].set_ylabel('Frequency')\n",
    "        axes[1, 0].set_title('Distribution of Pitch Ranges')\n",
    "    \n",
    "    if dataset_stats['composers']:\n",
    "        composers = list(dataset_stats['composers'].keys())[:10]\n",
    "        counts = [dataset_stats['composers'][c] for c in composers]\n",
    "        axes[1, 1].barh(composers, counts)\n",
    "        axes[1, 1].set_xlabel('Number of Files')\n",
    "        axes[1, 1].set_title('Top 10 Composers by File Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nDataset Summary:\")\n",
    "    print(f\"  Total notes: {np.sum(dataset_stats['total_notes']):,}\")\n",
    "    print(f\"  Average notes per file: {np.mean(dataset_stats['total_notes']):.1f}\")\n",
    "    print(f\"  Median notes per file: {np.median(dataset_stats['total_notes']):.1f}\")\n",
    "    \n",
    "    if dataset_stats['durations']:\n",
    "        print(f\"\\n  Total duration: {np.sum(dataset_stats['durations'])/3600:.2f} hours\")\n",
    "        print(f\"  Average duration: {np.mean(dataset_stats['durations']):.1f} seconds\")\n",
    "        print(f\"  Median duration: {np.median(dataset_stats['durations']):.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Composer-Specific Analysis\n",
    "\n",
    "Analyze statistics for specific composers of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_composers = ['bach', 'mozart', 'beethoven', 'chopin']\n",
    "\n",
    "composer_stats = {}\n",
    "\n",
    "for composer in target_composers:\n",
    "    composer_files = [f for f in all_midi_files if composer.lower() in str(f).lower()]\n",
    "    \n",
    "    if composer_files:\n",
    "        print(f\"\\nAnalyzing {composer.title()}: {len(composer_files)} files\")\n",
    "        composer_stats[composer] = collect_dataset_stats(composer_files, max_files=100)\n",
    "        \n",
    "        stats = composer_stats[composer]\n",
    "        if stats['total_notes']:\n",
    "            print(f\"  Avg notes: {np.mean(stats['total_notes']):.1f}\")\n",
    "            print(f\"  Avg duration: {np.mean(stats['durations']):.1f}s\" if stats['durations'] else \"  No duration info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "Based on this analysis:\n",
    "1. Identify appropriate sequence lengths for model training\n",
    "2. Determine if we need to chunk long pieces\n",
    "3. Filter out files that are too short/long\n",
    "4. Create train/validation/test splits per composer\n",
    "5. Design tokenization strategy based on pitch distributions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "composer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
